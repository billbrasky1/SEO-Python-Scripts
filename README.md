# SEOâ€‘Scraper Toolkit

Welcome!  
This repository contains a set of **plugâ€‘andâ€‘play Python utilities** that streamline repetitive technicalâ€‘SEO tasksâ€”crawling, archiving, and metadata extractionâ€”so you can spend more time on strategy and less on busywork.

> **Why share these?**  
> Iâ€™ve used variations of these scripts on dozens of audits and content projects. After scrubbing all clientâ€‘specific details (every URL, brand name, and personal reference has been replaced with generic placeholders), Iâ€™m openâ€‘sourcing the toolkit for the SEO community.

---

## ğŸ”§ What's Inside?

| Script | Purpose (oneâ€‘liner) |
| ------ | ------------------ |
| **HTML_Combiner.py** | Merge a folder of HTML files into one consolidated text file (handy for keyword analysis). |
| **internal_linking.py** | Crawl a list of URLs and export all internal links to CSV for architecture audits. |
| **json_html_scraper.py** | Fetch raw HTML for each URL via Selenium and save it to a JSON array. |
| **meta_tag_scraper.py** | Collect `<title>` and `<meta description>` from pagesâ€”perfect for quick meta audits. |
| **scrape_to_pdf.py** | Grab page content with Requests/BeautifulSoup and compile the results into a single PDF. |
| **stealthy_scraper.py** | Headless Selenium scraper with minimal footprint; outputs to PDF. |
| **ultra_stealthy_scraper.py** | A beefedâ€‘up version with rotating userâ€‘agents and random delays for extra stealth. |

All files start with a short docâ€‘string explaining what they do and where to drop your own inputs.

---

## ğŸš€ Quick Start

1. **Clone the repo**

   ```bash
   git clone https://github.com/yourâ€‘org/seoâ€‘scraperâ€‘toolkit.git
   cd seoâ€‘scraperâ€‘toolkit
Create a virtual environment (optional but recommended)

bash
Copy
Edit
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
Install dependencies

bash
Copy
Edit
pip install -r requirements.txt
Headsâ€‘up:
Some scripts rely on Selenium. Youâ€™ll need a compatible browser driver
(e.g., ChromeDriver) on your PATH.

Customize placeholders

The repo ships with the generic URL https://example.com/path.
Replace these with your targets before running:

python
Copy
Edit
TARGET_URLS = [
    "https://yourâ€‘site.com/pageâ€‘1",
    "https://yourâ€‘site.com/pageâ€‘2",
]
Run a script

bash
Copy
Edit
python meta_tag_scraper.py
Outputs land in the same folder (e.g., meta_tags.csv, archive.pdf, etc.).

ğŸ“„ Requirements
Pythonâ€¯3.8+

Common libraries (requests, beautifulsoup4, pandas, selenium, pdfkit, etc.)
â†’ see requirements.txt for the exact list

(Optional) Chrome or Firefox + the matching WebDriver for Selenium scripts

wkhtmltopdf if you use pdfkit

ğŸ™Œ Contributing
Fork the project & create your branch:
git checkout -b feature/awesomeâ€‘idea

Commit your changes:
git commit -m "feat: add awesome idea"

Push to the branch:
git push origin feature/awesomeâ€‘idea

Open a Pull Request ğŸš€

Bug reports, feature suggestions, and performance tweaks are all welcome.
Please keep any clientâ€‘specific data out of the PRs.

ğŸ“œ License
Released under the GNU General Public License v3.0.
See LICENSE for details.

âœ¨ Acknowledgements
Big thanks to the SEO and Python communities for continually sharing knowledge and tooling.
If you find this repo useful, feel free to â­ it, fork it, or drop feedback in Issues!

Happy scraping,

Daniel Brinker
